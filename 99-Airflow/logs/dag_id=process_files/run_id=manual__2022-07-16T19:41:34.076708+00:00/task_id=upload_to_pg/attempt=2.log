[2022-07-16 19:44:36,987] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: process_files.upload_to_pg manual__2022-07-16T19:41:34.076708+00:00 [queued]>
[2022-07-16 19:44:36,996] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: process_files.upload_to_pg manual__2022-07-16T19:41:34.076708+00:00 [queued]>
[2022-07-16 19:44:36,996] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-07-16 19:44:36,996] {taskinstance.py:1377} INFO - Starting attempt 2 of 2
[2022-07-16 19:44:36,996] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-07-16 19:44:37,008] {taskinstance.py:1397} INFO - Executing <Task(PostgresOperator): upload_to_pg> on 2022-07-16 19:41:34.076708+00:00
[2022-07-16 19:44:37,013] {standard_task_runner.py:52} INFO - Started process 3584 to run task
[2022-07-16 19:44:37,016] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'process_files', 'upload_to_pg', 'manual__2022-07-16T19:41:34.076708+00:00', '--job-id', '33', '--raw', '--subdir', 'DAGS_FOLDER/process_files.py', '--cfg-path', '/tmp/tmpjckw6097', '--error-file', '/tmp/tmp00a8n88c']
[2022-07-16 19:44:37,016] {standard_task_runner.py:80} INFO - Job 33: Subtask upload_to_pg
[2022-07-16 19:44:37,070] {task_command.py:371} INFO - Running <TaskInstance: process_files.upload_to_pg manual__2022-07-16T19:41:34.076708+00:00 [running]> on host 98d7be6daedb
[2022-07-16 19:44:37,134] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=process_files
AIRFLOW_CTX_TASK_ID=upload_to_pg
AIRFLOW_CTX_EXECUTION_DATE=2022-07-16T19:41:34.076708+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-07-16T19:41:34.076708+00:00
[2022-07-16 19:44:37,142] {base.py:68} INFO - Using connection ID 'pg_conn' for task execution.
[2022-07-16 19:44:37,144] {dbapi.py:231} INFO - Running statement: --
-- PostgreSQL port of the MySQL "World" database.
--
-- The sample data used in the world database is Copyright Statistics 
-- Finland, http://www.stat.fi/worldinfigures.
--

BEGIN;

SET client_encoding = 'LATIN1';

CREATE TABLE city (
    id integer NOT NULL,
    name text NOT NULL,
    countrycode character(3) NOT NULL,
    district text NOT NULL,
    population integer NOT NULL
);

CREATE TABLE country (
    code character(3) NOT NULL,
    name text NOT NULL,
    continent text NOT NULL,
    region text NOT NULL,
    surfacearea real NOT NULL,
    indepyear smallint,
    population integer NOT NULL,
    lifeexpectancy real,
    gnp numeric(10,2),
    gnpold numeric(10,2),
    localname text NOT NULL,
    governmentform text NOT NULL,
    headofstate text,
    capital integer,
    code2 character(2) NOT NULL,
    CONSTRAINT country_continent_check CHECK ((((((((continent = 'Asia'::text) OR (continent = 'Europe'::text)) OR (continent = 'North America'::text)) OR (continent = 'Africa'::text)) OR (continent = 'Oceania'::text)) OR (continent = 'Antarctica'::text)) OR (continent = 'South America'::text)))
);

CREATE TABLE countrylanguage (
    countrycode character(3) NOT NULL,
    "language" text NOT NULL,
    isofficial boolean NOT NULL,
    percentage real NOT NULL
);

COMMIT;, parameters: None
[2022-07-16 19:44:37,153] {postgres.py:94} INFO - WARNING:  there is already a transaction in progress

[2022-07-16 19:44:37,153] {postgres.py:94} INFO - WARNING:  there is no transaction in progress

[2022-07-16 19:44:37,164] {taskinstance.py:1420} INFO - Marking task as SUCCESS. dag_id=process_files, task_id=upload_to_pg, execution_date=20220716T194134, start_date=20220716T194436, end_date=20220716T194437
[2022-07-16 19:44:37,187] {local_task_job.py:156} INFO - Task exited with return code 0
[2022-07-16 19:44:37,218] {local_task_job.py:273} INFO - 1 downstream tasks scheduled from follow-on schedule check
