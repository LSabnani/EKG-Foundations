[2022-07-16 19:45:50,244] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: process_files.upload_to_pg manual__2022-07-16T19:45:34.681256+00:00 [queued]>
[2022-07-16 19:45:50,253] {taskinstance.py:1179} INFO - Dependencies all met for <TaskInstance: process_files.upload_to_pg manual__2022-07-16T19:45:34.681256+00:00 [queued]>
[2022-07-16 19:45:50,253] {taskinstance.py:1376} INFO - 
--------------------------------------------------------------------------------
[2022-07-16 19:45:50,253] {taskinstance.py:1377} INFO - Starting attempt 1 of 1
[2022-07-16 19:45:50,253] {taskinstance.py:1378} INFO - 
--------------------------------------------------------------------------------
[2022-07-16 19:45:50,265] {taskinstance.py:1397} INFO - Executing <Task(PostgresOperator): upload_to_pg> on 2022-07-16 19:45:34.681256+00:00
[2022-07-16 19:45:50,271] {standard_task_runner.py:52} INFO - Started process 3729 to run task
[2022-07-16 19:45:50,274] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'process_files', 'upload_to_pg', 'manual__2022-07-16T19:45:34.681256+00:00', '--job-id', '37', '--raw', '--subdir', 'DAGS_FOLDER/process_files.py', '--cfg-path', '/tmp/tmplfwfo2sn', '--error-file', '/tmp/tmptxy7tnr3']
[2022-07-16 19:45:50,274] {standard_task_runner.py:80} INFO - Job 37: Subtask upload_to_pg
[2022-07-16 19:45:50,326] {task_command.py:371} INFO - Running <TaskInstance: process_files.upload_to_pg manual__2022-07-16T19:45:34.681256+00:00 [running]> on host 98d7be6daedb
[2022-07-16 19:45:50,392] {taskinstance.py:1591} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=process_files
AIRFLOW_CTX_TASK_ID=upload_to_pg
AIRFLOW_CTX_EXECUTION_DATE=2022-07-16T19:45:34.681256+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-07-16T19:45:34.681256+00:00
[2022-07-16 19:45:50,400] {base.py:68} INFO - Using connection ID 'pg_conn' for task execution.
[2022-07-16 19:45:50,403] {dbapi.py:231} INFO - Running statement: --
-- PostgreSQL port of the MySQL "World" database.
--
-- The sample data used in the world database is Copyright Statistics 
-- Finland, http://www.stat.fi/worldinfigures.
--

BEGIN;

SET client_encoding = 'LATIN1';

CREATE TABLE city (
    id integer NOT NULL,
    name text NOT NULL,
    countrycode character(3) NOT NULL,
    district text NOT NULL,
    population integer NOT NULL
);

CREATE TABLE country (
    code character(3) NOT NULL,
    name text NOT NULL,
    continent text NOT NULL,
    region text NOT NULL,
    surfacearea real NOT NULL,
    indepyear smallint,
    population integer NOT NULL,
    lifeexpectancy real,
    gnp numeric(10,2),
    gnpold numeric(10,2),
    localname text NOT NULL,
    governmentform text NOT NULL,
    headofstate text,
    capital integer,
    code2 character(2) NOT NULL,
    CONSTRAINT country_continent_check CHECK ((((((((continent = 'Asia'::text) OR (continent = 'Europe'::text)) OR (continent = 'North America'::text)) OR (continent = 'Africa'::text)) OR (continent = 'Oceania'::text)) OR (continent = 'Antarctica'::text)) OR (continent = 'South America'::text)))
);

CREATE TABLE countrylanguage (
    countrycode character(3) NOT NULL,
    "language" text NOT NULL,
    isofficial boolean NOT NULL,
    percentage real NOT NULL
);

COMMIT;, parameters: None
[2022-07-16 19:45:50,404] {taskinstance.py:1909} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/providers/postgres/operators/postgres.py", line 92, in execute
    self.hook.run(self.sql, self.autocommit, parameters=self.parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 211, in run
    self._run_command(cur, sql_statement, parameters)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/hooks/dbapi.py", line 235, in _run_command
    cur.execute(sql_statement)
psycopg2.errors.DuplicateTable: relation "city" already exists

[2022-07-16 19:45:50,410] {taskinstance.py:1420} INFO - Marking task as FAILED. dag_id=process_files, task_id=upload_to_pg, execution_date=20220716T194534, start_date=20220716T194550, end_date=20220716T194550
[2022-07-16 19:45:50,419] {standard_task_runner.py:97} ERROR - Failed to execute job 37 for task upload_to_pg (relation "city" already exists
; 3729)
[2022-07-16 19:45:50,445] {local_task_job.py:156} INFO - Task exited with return code 1
[2022-07-16 19:45:50,480] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
